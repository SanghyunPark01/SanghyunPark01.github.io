---
title:  "[DL-study]Lec01-1"
excerpt: "Machine Learning의 개념과 Tensor Manipulation(1)"

categories:
  - DL_study
tags:
  - [Deep Learning, Machine Learning]

toc: true
toc_sticky: true
 
date: 2021-07-26
last_modified_at: 2021-07-26
---
# Before study
## 학습 목표
>* 기본적인 머신러닝(Machine Learning)개념에 대해 알아본다.
>* 텐서조작(Tensor Manipulation)에 대해 알아본다.  

## 핵심 키워드
>* 머신러닝(Machine Learning)  
>* 지도학습(Supervised Learning) / 비지도학습(Unsupervised Learning)  
>* 텐서(Tensor)
>* 넘파이(NumPy)
>* 텐서 조작(Tensor Manipulation)
>* 브로드캐스팅(Broadcasting)  

# 머신러닝(Machine Learning)
## 머신러닝 이란?
인공지능의 한 분야이고, 1959년 아서사무엘은 머신러닝을 “컴퓨터에 명시적인 프로그램 없이 배울 수 있는 능력을 부여하는 연구 분야”라고 정의하였다. 즉 사람이 학습하듯이 컴퓨터에도 데이터들을 줘서 학습하게 함으로써 새로운 지식을 얻어내게 하는 것이다.
## Learning의 종류
Learning은 학습의 방법에 따라 두 가지로 나눠진다.
* 지도학습(Supervised Learning)
* 비지도학습(Unsupervised Learning)  

**지도학습(Supervised Learning)**  
Input Data와 Input Data에 대한 정답에 해당하는 Label정보를 입력으로 받는다. 그리고, 주어진 데이터와 label로부터 모델을 학습시켜 새로운 데이터를 입력으로 받았을 때 label을 예측하는 방법이다.  
**비지도학습(Unsupervised Learning)**  
지도학습과 반대로 모델의 입력값으로 오직 Input data만 주어진다. 그래서, 데이터 분석을 통해 unknown pattern을 학습하고 새로운 데이터를 입력으로 받았을 때 분류해주는 방법이다.  

## 지도학습(Supervised Learning)
지도학습은 3가지 종류가 있다.  
* Regression
* Binary classification
* Multi-lable classification

위에 내용들은 나중에 자세히 다뤄보도록 한다.

---  

# 텐서 조작(Tensor Manipulation)
## 1. 벡터, 행렬, 텐서 (Vector, Matrix and Tensor)
### 1) 벡터, 행렬, 텐서는 무엇일가?  
<p align="center"><img src="https://user-images.githubusercontent.com/77342519/126922365-f2028eb9-55a0-41fa-9766-0b7011e389c8.PNG"></p>  
기본적으로 차원이 없는 값을 스칼라(Scalar)라고 하며, 1차원으로 구성된 값은 벡터(Vector), 2차원으로 구성된 값을 행렬(Matrix), 3차원으로 구성된 값을 텐서(Tensor)라고 부른다. 4차원 이상부터는 3차원의 텐서를 이용해 확장한 모습과 같다.  

### 2) PyTorch Tensor Shape Convention  
**2D Tensor (Typical Simple Setting)**
<p align="center"><img src="https://user-images.githubusercontent.com/77342519/126923256-d49af22e-6224-4b0b-ba10-3a1d31a74427.PNG" width="30%" height="30%" ></p>

* 크기 :  &#124; t &#124;=(batch size,dim)  
* batch size : 세로  
* dim : 가로  
* ex )  
```python
[[1,2,3,4,5],[6,7,8,9,10]] 
```  
위와 같은 표현은 2 x 5(batch size, dim)의 크기를 가지는 2D Tensor이다.  

**3D Tensor (Typical Computer Vision)**  
<p align="center"><img src="https://user-images.githubusercontent.com/77342519/126924954-3240ed6b-07e0-4bf6-b6bd-b1ec21c7aae7.png"></p>

* 크기 : &#124; t &#124;=(batch size,width,height)  
* batch size : 높이  
* width : 가로 / height : 세로  
* 일반적으로 자연어 처리보다 비전분야에서는 더 복잡한 텐서를 다루게 된다. 이미지는 가로 와 세로로 구성되고 여러장의 이미지를 batch size로 구성하게 되면 3차원 Tensor가 된다.  

**3D Tensor (Typical Natural Language Processing)**  
NLP분야에서 3차원 텐서이다.  
<p align="center"><img src="https://user-images.githubusercontent.com/77342519/126924954-3240ed6b-07e0-4bf6-b6bd-b1ec21c7aae7.png"></p>

* 크기 : &#124; t &#124;=(batch size,length,dim)  
* ex )  
```python
[[나는 사과를 좋아해], [나는 바나나를 좋아해], [나는 사과를 싫어해], [나는 바나나를 싫어해]]
```  
한문장이 한 단어라 생각하면 4 X 1의 2D Tensor 이다.  
단어로 쪼개보면,   
```python
[['나는', '사과를', '좋아해'], ['나는', '바나나를', '좋아해'], ['나는', '사과를', '싫어해'], ['나는', '바나나를', '싫어해']]
```  
이며, 이 훈련 데이터의 크기는 4 x 3의 크기를 가지는 2D Tensor 이다.  
컴퓨터는 텍스트보다 숫자를 더 잘 처리하기 때문에, 각 단어를 벡터로 만들어주면, 아래와 같이 예를들어 2차원 벡터로 변환했다 하자.  
```python
'나는' = [0.1, 0.2]
'사과를' = [0.4, 0.7]
'바나나를' = [0.1, 0.5]
'좋아해' = [0.3, 0.2]
'싫어해' = [0.6, 0.8]
```  
훈련 데이터를 재구성 하면 아래와 같다.  
```python
[[[0.1, 0.2], [0.4, 0.7], [0.3, 0.2]],
 [[0.1, 0.2], [0.1, 0.5], [0.3, 0.2]],
 [[0.1, 0.2], [0.4, 0.7], [0.6, 0.8]],
 [[0.1, 0.2], [0.1, 0.5], [0.6, 0.8]]]
 ```  
 이 훈련데이터는 4 x 3 x 2의 크기를 가지는 3D Tensor이다.  
 컴퓨터는 배치단위로 연산을 수행하므로 위 데이터의 batch size를 2로 나누어 2번 연산하게 할 수 있다.  

## 2. Numpy Review
Pytorch는 Numpy와 매우 유사하기 때문에 먼저 Numpy부터 살펴보자. 우선 numpy를 import 한다.


```python
import numpy as np
```

Numpy로 텐서를 만들어보자.  
### 1) 1D with Numpy  
Numpy로 1차원 Tensor인 Vector를 만들어 보자.  


```python
t=np.array([0.,1.,2.,3.,4.,5.,6.])
print(t)
```

    [0. 1. 2. 3. 4. 5. 6.]
    

벡터의 차원과 크기를 출력해보자.  


```python
print('차원 : ',t.ndim)
print('크기 : ',t.shape)
```

    차원 :  1
    크기 :  (7,)
    

.ndim은 몇차원인지 반환해준다. 1차원의 텐서는 벡터 이므로 1차원이 출력된다.  
.shape는 크기를 반환해준다. (7,)은 (1,7)을 의미한다. 즉, 1 x 7 의 크기를 가지는 벡터이다.  
### 2) 2D with Numpy  
Numpy로 2차원 Tensor인 Matrix를 만들어 보자.  


```python
t=np.array([[1.,2.,3.],[4.,5.,6.],[7.,8.,9],[10.,11.,12]])
print(t)
```

    [[ 1.  2.  3.]
     [ 4.  5.  6.]
     [ 7.  8.  9.]
     [10. 11. 12.]]
    


```python
print('차원 : ',t.ndim)
print('크기 : ',t.shape)
```

    차원 :  2
    크기 :  (4, 3)
    

.ndim과 .shape는 위에서 Vector에서 설명했던것과 같다.  

위와 같은 방법으로 3차원 텐서도 만들 수 있다.  

## 다음 포스트 
PyTorch로 텐서 만들기